{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35cf7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec64f2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 files to merge.\n"
     ]
    }
   ],
   "source": [
    "path = \"Raw Post\"  \n",
    "all_files = glob.glob(f\"{path}/*_Comments.csv\")\n",
    "print(f\"Found {len(all_files)} files to merge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a956ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged 54 files into one DataFrame with 3593 rows and 6 columns.\n",
      "Saved merged file to 'merged_comments_post.csv'.\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for f in all_files:\n",
    "    try:\n",
    "        df = pd.read_csv(f, sep=\";\")\n",
    "    except:\n",
    "        df = pd.read_csv(f, sep=None, engine='python')\n",
    "    df_list.append(df)\n",
    "\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "print(f\"Merged {len(df_list)} files into one DataFrame with \"\n",
    "      f\"{merged_df.shape[0]} rows and {merged_df.shape[1]} columns.\")\n",
    "\n",
    "merged_df.to_csv(f\"{path}/merged_comments_post.csv\", index=False)\n",
    "print(\"Saved merged file to 'merged_comments_post.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbfc8587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          comment_id  created_at  \\\n",
      "0  17861947392214179  1724336300   \n",
      "1  17937193913894509  1724336415   \n",
      "2  17891185992070024  1724336530   \n",
      "3  17912206535989525  1724336543   \n",
      "4  17920529441958210  1724337269   \n",
      "\n",
      "                                     profile_pic_url  \\\n",
      "0  https://scontent-lax3-1.cdninstagram.com/v/t51...   \n",
      "1  https://scontent-lax3-1.cdninstagram.com/v/t51...   \n",
      "2  https://scontent-lax3-2.cdninstagram.com/v/t51...   \n",
      "3  https://scontent-lax3-1.cdninstagram.com/v/t51...   \n",
      "4  https://scontent-lax3-1.cdninstagram.com/v/t51...   \n",
      "\n",
      "                                  text      user_id       username  \n",
      "0  I chase survival to the finish line   3507810387   hendyhariadi  \n",
      "1                               Gassss   1129256812       przfghtr  \n",
      "2                                  ðŸ”¥ðŸ”¥ðŸ”¥    336813685  pittyuurasyid  \n",
      "3                                 ðŸ”¥ðŸ”¥ðŸ”¥ðŸ™Œ  13833614825      astriidkz  \n",
      "4                                  ðŸ”¥ðŸ”¥ðŸ”¥    510675608      andri_lou  \n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b23bc99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (3593, 6)\n",
      "          comment_id  created_at  \\\n",
      "0  17861947392214179  1724336300   \n",
      "1  17937193913894509  1724336415   \n",
      "2  17891185992070024  1724336530   \n",
      "3  17912206535989525  1724336543   \n",
      "4  17920529441958210  1724337269   \n",
      "\n",
      "                                     profile_pic_url  \\\n",
      "0  https://scontent-lax3-1.cdninstagram.com/v/t51...   \n",
      "1  https://scontent-lax3-1.cdninstagram.com/v/t51...   \n",
      "2  https://scontent-lax3-2.cdninstagram.com/v/t51...   \n",
      "3  https://scontent-lax3-1.cdninstagram.com/v/t51...   \n",
      "4  https://scontent-lax3-1.cdninstagram.com/v/t51...   \n",
      "\n",
      "                                  text      user_id       username  \n",
      "0  I chase survival to the finish line   3507810387   hendyhariadi  \n",
      "1                               Gassss   1129256812       przfghtr  \n",
      "2                                  ðŸ”¥ðŸ”¥ðŸ”¥    336813685  pittyuurasyid  \n",
      "3                                 ðŸ”¥ðŸ”¥ðŸ”¥ðŸ™Œ  13833614825      astriidkz  \n",
      "4                                  ðŸ”¥ðŸ”¥ðŸ”¥    510675608      andri_lou  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"Raw Post/merged_comments_post.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78158662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   created_at       created_at_str\n",
      "0  1724336300  2024-08-22 14:18:20\n",
      "1  1724336415  2024-08-22 14:20:15\n",
      "2  1724336530  2024-08-22 14:22:10\n",
      "3  1724336543  2024-08-22 14:22:23\n",
      "4  1724337269  2024-08-22 14:34:29\n"
     ]
    }
   ],
   "source": [
    "df[\"created_at_readable\"] = pd.to_datetime(df[\"created_at\"], unit=\"s\")\n",
    "df[\"created_at_str\"] = df[\"created_at_readable\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(df[[\"created_at\", \"created_at_str\"]].head())\n",
    "df.to_csv(f\"{path}/merged_comments_post_new.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
